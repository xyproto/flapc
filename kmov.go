package main

import (
	"fmt"
	"os"
)

// KMOV* - Move to/from mask registers
//
// Essential for Flap's mask/predicate operations:
//   - Extracting mask results to general purpose registers
//   - Testing conditions from vector comparisons
//   - Counting active elements in masks
//   - Conditional execution based on masks
//
// Example usage in Flap:
//   comparison_mask = values ||> cmp_gt(threshold)
//   if any(comparison_mask) { ... }
//   count = popcount(comparison_mask)
//
// Architecture details:
//   x86-64: KMOVW/KMOVD/KMOVQ k1, r32/r64 (AVX-512)
//   ARM64:  MOV x0, p0 via PTEST + CSET (SVE2)
//   RISC-V: VPOPC.M rd, vs2 (RVV - population count)

// KMovMaskToGP moves mask register to general purpose register
// dst = mask (as integer bitmask)
func (o *Out) KMovMaskToGP(dst, src string) {
	switch o.target.Arch() {
	case ArchX86_64:
		o.kmovX86MaskToGP(dst, src)
	case ArchARM64:
		o.kmovARM64MaskToGP(dst, src)
	case ArchRiscv64:
		o.kmovRISCVMaskToGP(dst, src)
	}
}

// KMovGPToMask moves general purpose register to mask register
// dst = mask created from integer bitmask
func (o *Out) KMovGPToMask(dst, src string) {
	switch o.target.Arch() {
	case ArchX86_64:
		o.kmovX86GPToMask(dst, src)
	case ArchARM64:
		o.kmovARM64GPToMask(dst, src)
	case ArchRiscv64:
		o.kmovRISCVGPToMask(dst, src)
	}
}

// KMovMaskToMask moves between mask registers
// dst = src
func (o *Out) KMovMaskToMask(dst, src string) {
	switch o.target.Arch() {
	case ArchX86_64:
		o.kmovX86MaskToMask(dst, src)
	case ArchARM64:
		o.kmovARM64MaskToMask(dst, src)
	case ArchRiscv64:
		o.kmovRISCVMaskToMask(dst, src)
	}
}

// ============================================================================
// x86-64 AVX-512 implementation - Mask to GP
// ============================================================================

// x86-64 KMOVW r32, k1
// VEX.L0.0F.W0 93 /r
func (o *Out) kmovX86MaskToGP(dst, src string) {
	dstReg, dstOk := GetRegister(o.target.Arch(), dst)
	srcMask, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	if VerboseMode {
		fmt.Fprintf(os.Stderr, "kmovw %s, %s:", dst, src)
	}

	// VEX.L0.0F.W0 93 /r
	o.Write(0xC5)

	vex1 := uint8(0xF8) // map=0F, L=0, W=0
	if (dstReg.Encoding & 8) == 0 {
		vex1 |= 0x04
	}
	o.Write(vex1)

	o.Write(0x93) // KMOVW opcode

	modrm := uint8(0xC0) | ((dstReg.Encoding & 7) << 3) | (srcMask.Encoding & 7)
	o.Write(modrm)

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// x86-64 AVX-512 implementation - GP to Mask
// ============================================================================

// x86-64 KMOVW k1, r32
// VEX.L0.0F.W0 92 /r
func (o *Out) kmovX86GPToMask(dst, src string) {
	dstMask, dstOk := GetRegister(o.target.Arch(), dst)
	srcReg, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	if VerboseMode {
		fmt.Fprintf(os.Stderr, "kmovw %s, %s:", dst, src)
	}

	// VEX.L0.0F.W0 92 /r
	o.Write(0xC5)

	vex1 := uint8(0xF8)
	if (srcReg.Encoding & 8) == 0 {
		vex1 |= 0x04
	}
	o.Write(vex1)

	o.Write(0x92) // KMOVW opcode

	modrm := uint8(0xC0) | ((dstMask.Encoding & 7) << 3) | (srcReg.Encoding & 7)
	o.Write(modrm)

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// x86-64 AVX-512 implementation - Mask to Mask
// ============================================================================

// x86-64 KMOVW k1, k2
// VEX.L0.0F.W0 90 /r
func (o *Out) kmovX86MaskToMask(dst, src string) {
	dstMask, dstOk := GetRegister(o.target.Arch(), dst)
	srcMask, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	if VerboseMode {
		fmt.Fprintf(os.Stderr, "kmovw %s, %s:", dst, src)
	}

	// VEX.L0.0F.W0 90 /r
	o.Write(0xC5)
	o.Write(0xF8) // map=0F, L=0, W=0, vvvv=1111
	o.Write(0x90) // KMOVW opcode

	modrm := uint8(0xC0) | ((dstMask.Encoding & 7) << 3) | (srcMask.Encoding & 7)
	o.Write(modrm)

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// ARM64 SVE2 implementation - Mask to GP
// ============================================================================

func (o *Out) kmovARM64MaskToGP(dst, src string) {
	dstReg, dstOk := GetRegister(o.target.Arch(), dst)
	_, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	// SVE doesn't have direct predicate→GP move
	// Would use PTEST to set flags, then CSET to capture
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "# SVE predicate to GP requires PTEST + CSET\\n")
	}
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "ptest p7, %s.b  # Test predicate\\n", src)
	}
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "cset %s, ne:", dst)
	}

	// CSET encoding - conditional set
	// 1 0 0 11010100 cond 0 0 0 0 1 11111 Rd
	// cond=0001 (NE - not equal, any bit set)
	instr := uint32(0x9A9F17E0) |
		(1 << 12) | // cond=NE
		uint32(dstReg.Encoding&31) // Rd

	o.Write(uint8(instr & 0xFF))
	o.Write(uint8((instr >> 8) & 0xFF))
	o.Write(uint8((instr >> 16) & 0xFF))
	o.Write(uint8((instr >> 24) & 0xFF))

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// ARM64 SVE2 implementation - GP to Mask
// ============================================================================

func (o *Out) kmovARM64GPToMask(dst, src string) {
	_, dstOk := GetRegister(o.target.Arch(), dst)
	_, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	// SVE doesn't have direct GP→predicate move
	// Would need to create vector with bits, then compare
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "# SVE GP to predicate requires vector construction\\n")
	}
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "# Use WHILELO or comparison to create predicate mask\\n")
	}

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// ARM64 SVE2 implementation - Mask to Mask
// ============================================================================

func (o *Out) kmovARM64MaskToMask(dst, src string) {
	dstMask, dstOk := GetRegister(o.target.Arch(), dst)
	srcMask, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	// SVE predicate move via ORR
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "mov %s.b, %s.b:", dst, src)
	}

	// SVE ORR predicates (implemented as mov)
	// 00100101 10 00 0000 01 0 Pm 0 Pg Pdn
	instr := uint32(0x25804000) |
		(uint32(srcMask.Encoding&15) << 5) | // Pm (source)
		(uint32(srcMask.Encoding&15) << 10) | // Pg (also source for mov)
		uint32(dstMask.Encoding&15) // Pdn (dest)

	o.Write(uint8(instr & 0xFF))
	o.Write(uint8((instr >> 8) & 0xFF))
	o.Write(uint8((instr >> 16) & 0xFF))
	o.Write(uint8((instr >> 24) & 0xFF))

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// RISC-V RVV implementation - Mask to GP
// ============================================================================

// RISC-V vpopc.m rd, vs2, vm
// Population count of mask - count set bits
func (o *Out) kmovRISCVMaskToGP(dst, src string) {
	dstReg, dstOk := GetRegister(o.target.Arch(), dst)
	srcMask, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	if VerboseMode {
		fmt.Fprintf(os.Stderr, "vpopc.m %s, %s:", dst, src)
	}

	// vpopc.m encoding
	// funct6=010000, vm=1, rs1=10000, funct3=010 (mask dest)
	instr := uint32(0x57) |
		(2 << 12) | // funct3=010
		(uint32(dstReg.Encoding&31) << 7) |
		(16 << 15) | // rs1=10000 (POPC)
		(uint32(srcMask.Encoding&31) << 20) |
		(1 << 25) | // vm=1
		(0x10 << 26) // funct6=010000

	o.Write(uint8(instr & 0xFF))
	o.Write(uint8((instr >> 8) & 0xFF))
	o.Write(uint8((instr >> 16) & 0xFF))
	o.Write(uint8((instr >> 24) & 0xFF))

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// RISC-V RVV implementation - GP to Mask
// ============================================================================

func (o *Out) kmovRISCVGPToMask(dst, src string) {
	_, dstOk := GetRegister(o.target.Arch(), dst)
	_, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	// RVV doesn't have direct GP→mask move
	// Would create vector from scalar and compare
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "# RVV GP to mask requires vector construction\\n")
	}
	if VerboseMode {
		fmt.Fprintf(os.Stderr, "# Use vmv.v.x + comparison to create mask\\n")
	}

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}

// ============================================================================
// RISC-V RVV implementation - Mask to Mask
// ============================================================================

// RISC-V vmand.mm vd, vs2, vs1
// Mask-to-mask AND (can use with same source for move)
func (o *Out) kmovRISCVMaskToMask(dst, src string) {
	dstMask, dstOk := GetRegister(o.target.Arch(), dst)
	srcMask, srcOk := GetRegister(o.target.Arch(), src)
	if !dstOk || !srcOk {
		return
	}

	if VerboseMode {
		fmt.Fprintf(os.Stderr, "vmand.mm %s, %s, %s:", dst, src, src)
	}

	// vmand.mm encoding (and mask with itself = copy)
	// funct6=011001, vm=1, funct3=010
	instr := uint32(0x57) |
		(2 << 12) | // funct3=010
		(uint32(dstMask.Encoding&31) << 7) |
		(uint32(srcMask.Encoding&31) << 15) | // vs1
		(uint32(srcMask.Encoding&31) << 20) | // vs2
		(1 << 25) | // vm=1
		(0x19 << 26) // funct6=011001

	o.Write(uint8(instr & 0xFF))
	o.Write(uint8((instr >> 8) & 0xFF))
	o.Write(uint8((instr >> 16) & 0xFF))
	o.Write(uint8((instr >> 24) & 0xFF))

	if VerboseMode {
		fmt.Fprintln(os.Stderr)
	}
}
