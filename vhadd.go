package main

import (
	"fmt"
	"os"
)

// VHADDPD - Horizontal add of packed double-precision floats
//
// Essential for Flap's reduction operations:
//   - Tree-based parallel reductions
//   - Sum across vector lanes
//   - Dot product accumulation
//   - Fast aggregation operations
//
// Example usage in Flap:
//   total = values ||> hadd ||> hadd ||> hadd  # Reduce to scalar
//   partial_sums = hadd(vec1, vec2)             # Pairwise sums
//
// Architecture details:
//   x86-64: VHADDPD ymm1, ymm2, ymm3 (AVX/SSE3)
//   ARM64:  FADDP zd.d, pg/m, zn.d (SVE2 pairwise add)
//   RISC-V: Manual shuffles + VFADD.VV (no native hadd)
//
// Note: AVX-512 removed VHADDPD, prefer regular adds with shuffles

// VHAddPDVectorToVector performs horizontal add
// dst[0] = src1[0] + src1[1]
// dst[1] = src2[0] + src2[1]
// dst[2] = src1[2] + src1[3]
// dst[3] = src2[2] + src2[3]
func (o *Out) VHAddPDVectorToVector(dst, src1, src2 string) {
	switch o.machine {
	case MachineX86_64:
		o.vhaddpdX86VectorToVector(dst, src1, src2)
	case MachineARM64:
		o.vhaddARM64VectorToVector(dst, src1, src2)
	case MachineRiscv64:
		o.vhaddRISCVVectorToVector(dst, src1, src2)
	}
}

// ============================================================================
// x86-64 AVX/SSE3 implementation
// ============================================================================

// x86-64 VHADDPD ymm1, ymm2, ymm3/m256
// VEX.NDS.256.66.0F.WIG 7C /r
func (o *Out) vhaddpdX86VectorToVector(dst, src1, src2 string) {
	dstReg, dstOk := GetRegister(o.machine, dst)
	src1Reg, src1Ok := GetRegister(o.machine, src1)
	src2Reg, src2Ok := GetRegister(o.machine, src2)
	if !dstOk || !src1Ok || !src2Ok {
		return
	}

	fmt.Fprintf(os.Stderr, "vhaddpd %s, %s, %s:", dst, src1, src2)

	if dstReg.Size == 512 {
		// AVX-512 removed VHADDPD
		// Use shuffles + regular add instead
		fmt.Fprintf(os.Stderr, " (no AVX-512 VHADDPD)")
		fmt.Fprintf(os.Stderr, "\n# Use VSHUFPD + VADDPD for horizontal add")
	} else if dstReg.Size == 256 {
		// AVX VHADDPD
		fmt.Fprintf(os.Stderr, " (AVX)")

		o.Write(0xC4)

		vex1 := uint8(0x01) // map=0F
		if (dstReg.Encoding & 8) == 0 {
			vex1 |= 0x80
		}
		if (src2Reg.Encoding & 8) == 0 {
			vex1 |= 0x20
		}
		vex1 |= 0x40
		o.Write(vex1)

		vex2 := uint8(0x05)                            // pp=01 (66), L=1, W=0
		vex2 |= uint8((^src1Reg.Encoding & 0x0F) << 3) // vvvv
		o.Write(vex2)

		o.Write(0x7C) // VHADDPD opcode

		modrm := uint8(0xC0) | ((dstReg.Encoding & 7) << 3) | (src2Reg.Encoding & 7)
		o.Write(modrm)
	} else {
		// SSE3 HADDPD
		fmt.Fprintf(os.Stderr, " (SSE3)")

		o.Write(0x66) // mandatory prefix
		o.Write(0x0F)
		o.Write(0x7C)

		modrm := uint8(0xC0) | ((dstReg.Encoding & 7) << 3) | (src2Reg.Encoding & 7)
		o.Write(modrm)
	}

	fmt.Fprintln(os.Stderr)
}

// ============================================================================
// ARM64 SVE2/NEON implementation
// ============================================================================

func (o *Out) vhaddARM64VectorToVector(dst, src1, src2 string) {
	dstReg, dstOk := GetRegister(o.machine, dst)
	src1Reg, src1Ok := GetRegister(o.machine, src1)
	src2Reg, src2Ok := GetRegister(o.machine, src2)
	if !dstOk || !src1Ok || !src2Ok {
		return
	}

	if dstReg.Size == 512 {
		// SVE FADDP - pairwise add
		fmt.Fprintf(os.Stderr, "# SVE horizontal add: use FADDP\\n")
		fmt.Fprintf(os.Stderr, "faddp %s.d, p7/m, %s.d:", dst, src1)

		// SVE FADDP encoding
		// 01100100 11 0 10000 101 Pg Zn Zd
		instr := uint32(0x64905000) |
			(7 << 10) | // Pg=p7
			(uint32(src1Reg.Encoding&31) << 5) | // Zn
			uint32(dstReg.Encoding&31) // Zd

		o.Write(uint8(instr & 0xFF))
		o.Write(uint8((instr >> 8) & 0xFF))
		o.Write(uint8((instr >> 16) & 0xFF))
		o.Write(uint8((instr >> 24) & 0xFF))

		fmt.Fprintf(os.Stderr, "\n# Note: SVE FADDP only uses one source\\n")
	} else {
		// NEON FADDP
		fmt.Fprintf(os.Stderr, "faddp %s.2d, %s.2d, %s.2d:", dst, src1, src2)

		// NEON FADDP encoding
		// 0 Q 1 01110 0 sz 1 Rm 110 1 01 Rn Rd
		// Q=1, sz=1 (double)
		instr := uint32(0x6EC0D400) |
			(uint32(src2Reg.Encoding&31) << 16) |
			(uint32(src1Reg.Encoding&31) << 5) |
			uint32(dstReg.Encoding&31)

		o.Write(uint8(instr & 0xFF))
		o.Write(uint8((instr >> 8) & 0xFF))
		o.Write(uint8((instr >> 16) & 0xFF))
		o.Write(uint8((instr >> 24) & 0xFF))
	}

	fmt.Fprintln(os.Stderr)
}

// ============================================================================
// RISC-V RVV implementation
// ============================================================================

func (o *Out) vhaddRISCVVectorToVector(dst, src1, src2 string) {
	dstReg, dstOk := GetRegister(o.machine, dst)
	src1Reg, src1Ok := GetRegister(o.machine, src1)
	src2Reg, src2Ok := GetRegister(o.machine, src2)
	if !dstOk || !src1Ok || !src2Ok {
		return
	}

	// RVV doesn't have native horizontal add
	// Would need to shuffle and add manually
	fmt.Fprintf(os.Stderr, "# RVV horizontal add: shuffle + add\\n")
	fmt.Fprintf(os.Stderr, "# vslidedown + vfadd.vv\\n")
	fmt.Fprintf(os.Stderr, "vfadd.vv %s, %s, %s:", dst, src1, src2)

	// vfadd.vv encoding (placeholder - would need shuffle first)
	// funct6=000000, vm=1, funct3=001 (OPFVV)
	instr := uint32(0x57) |
		(1 << 12) | // funct3=001
		(uint32(dstReg.Encoding&31) << 7) |
		(uint32(src2Reg.Encoding&31) << 15) | // vs1
		(uint32(src1Reg.Encoding&31) << 20) | // vs2
		(1 << 25) | // vm=1
		(0x00 << 26) // funct6=000000

	o.Write(uint8(instr & 0xFF))
	o.Write(uint8((instr >> 8) & 0xFF))
	o.Write(uint8((instr >> 16) & 0xFF))
	o.Write(uint8((instr >> 24) & 0xFF))

	fmt.Fprintln(os.Stderr)
}
